---
title: "Spanish CDI explorations"
author: "Paulina & Mike"
date: "2022-10-13"
output: html_document
---

# Intro

Goal of this project is to use the five Spanish CDI datasets in Wordbank to try and investigate dialect variation in Spanish language acquisition. 

Here are some potential questions:

* Do the sumscores across the intersecting items look the same at the population level (correcting for demographics)?
* Do individual common items have similar psychometric / developmental properties?
* What are the properties of items with the same unilemma but different item definitions?
* What are the properties of items that are not shared across dialects? (Could also compare Spanish (Mexican) between monolingual and bilingual populations)


```{r setup}
library(tidyverse)
library(wordbankr)
library(arm)
```

# Data loading

Start with summary scores. 

```{r}
eu_ws <- get_administration_data(language = "Spanish (European)", 
                                 form = "WS", 
                                 include_demographic_info = TRUE)
mx_ws <- get_administration_data(language = "Spanish (Mexican)", 
                                 form = "WS", 
                                 include_demographic_info = TRUE)
pr_ws <- get_administration_data(language = "Spanish (Peruvian)", 
                                 form = "WS", 
                                 include_demographic_info = TRUE)
ar_ws <- get_administration_data(language = "Spanish (Argentinian)", 
                                 form = "WS", 
                                 include_demographic_info = TRUE)

sp_ws <- bind_rows(eu_ws, 
                   mx_ws, 
                   pr_ws, 
                   ar_ws)
```

Make a plot!

```{r}
ggplot(sp_ws, aes(x = age, y = production)) + 
  geom_jitter(width = .2, alpha = .2) + 
  geom_smooth() + 
  facet_wrap(~language)
```


# Comparison on the intersection of items

QUESTION: Do the sumscores across the intersecting items look the same at the population level (correcting for demographics)?

```{r}
langs <- c("Spanish (European)", "Spanish (Mexican)", "Spanish (Peruvian)", "Spanish (Argentinian)")

d_ws <- map_df(langs, function(x) get_instrument_data(language = x, 
                                                      form = "WS", 
                                                      administration_info = TRUE, 
                                                      item_info = TRUE))
```

Find the overlapping unilemmas.

For now, pull those unilemmas that are 1) in all languages, 2) only once in each language. 

```{r}
items <- map_df(langs, function(x) get_item_data(language = x, form = "WS"))

intersection <- items |>
  group_by(uni_lemma) |>
  summarise(n_langs = length(unique(language)), 
            n = n()) |>
  filter(n_langs == 4, n == 4) |>
  pull(uni_lemma)
# 224 common items
``` 

Filter data and replot. 

```{r}
ms_ws <- d_ws |>
  filter(uni_lemma %in% intersection) |>
  group_by(child_id, language, age) |>
  summarise(produces = sum(produces))

ggplot(ms_ws, aes(x = age, y = produces)) + 
  geom_jitter(width = .2, alpha = .2) + 
  geom_smooth() + 
  facet_wrap(~language)
```



# Comparison of developmental properties

QUESTION: Do individual common items have similar psychometric / developmental properties?

```{r}
source("scripts/fit_models.R")

wb_data <- d_ws |> 
  filter(uni_lemma %in% intersection) |>
  group_by(uni_lemma, language, age) |> 
  summarise(total = n(),
            num_true = sum(produces, na.rm = TRUE))

aoas <- fit_aoas(wb_data)
```

```{r}
ggplot(data = aoas) +
  geom_histogram(aes(x = aoa))+ 
  facet_wrap(~language)
```

Calculate correlations between languages

```{r}
cor_data <- aoas |> 
  pivot_wider(id_cols = uni_lemma, 
              names_from = language,
              values_from = aoa) |> 
  ungroup()

correl <- cor(cor_data |> dplyr::select(-"uni_lemma"), use = "complete.obs")
```

Plot correlogram
```{r}
library(corrgram)
corrgram(correl, type = "cor", panel = panel.cor)
```

```{r}
plot_data <- cor_data |> 
  pivot_longer(cols = c(`Spanish (Argentinian)`, `Spanish (Mexican)`, `Spanish (Peruvian)`), 
               names_to = "Dialect")
ggplot(plot_data, aes(x = `Spanish (European)`, y = value, col = Dialect)) + 
  geom_abline(slope = 1, intercept = 0, lty = "dashed", col = "#444444") +
  geom_point(alpha=.3) +
  geom_smooth(method = "lm") +
  theme_classic() + 
  theme(legend.position = "bottom") +
  labs(x = "Spanish (European) AoA",
       y = "Spanish (Latin American) AoA") +
  coord_cartesian(xlim = c(0, 40), ylim = c(0, 40))
```

Calculate differences in age of acquisition (AoA) between all dialects for each unilemma
```{r}
clean_aoas <- aoas |>
  dplyr::select(uni_lemma, language, aoa) |>
  pivot_wider(names_from = language, values_from = aoa)

difference_argentinian_european <- data.frame(difference_argentinian_european = c(clean_aoas$`Spanish (Argentinian)`- clean_aoas$`Spanish (European)`))

difference_argentinian_mexican <- data.frame(difference_argentinian_mexican = c(clean_aoas$`Spanish (Argentinian)`- clean_aoas$`Spanish (Mexican)`))

difference_argentinian_peruvian <- data.frame(difference_argentinian_peruvian = c(clean_aoas$`Spanish (Argentinian)`- clean_aoas$`Spanish (Peruvian)`))

difference_european_mexican <- data.frame(difference_european_mexican = c(clean_aoas$`Spanish (European)`- clean_aoas$`Spanish (Mexican)`))

difference_european_peruvian <- data.frame(difference_european_peruvian = c(clean_aoas$`Spanish (European)`- clean_aoas$`Spanish (Peruvian)`))

difference_mexican_peruvian <- data.frame(difference_mexican_peruvian = c(clean_aoas$`Spanish (Mexican)`- clean_aoas$`Spanish (Peruvian)`))

difference_AoA <- data.frame(uni_lemma = c(clean_aoas$uni_lemma), difference_argentinian_european, difference_argentinian_mexican, difference_argentinian_peruvian, difference_european_mexican, difference_european_peruvian, difference_mexican_peruvian)
```

Permutation testing on dialect correlations
```{r} 
# Function to perform permutation test
perm_test <- function(dialect1, dialect2, n_permutations = 10000) {
  
  # Remove NA values
  valid_indices <- complete.cases(dialect1, dialect2)
  dialect1 <- dialect1[valid_indices]
  dialect2 <- dialect2[valid_indices]
  
  # Check for zero variance
  if (var(dialect1) == 0 | var(dialect2) == 0) {
    return(NA)
  }
  
  observed_correlation <- cor(dialect1, dialect2)
  permuted_correlations <- numeric(n_permutations)
  
  for (i in 1:n_permutations) {
    permuted_dialect2 <- sample(dialect2)
    permuted_correlations[i] <- cor(dialect1, permuted_dialect2)
  }
  
  p_value <- mean(permuted_correlations >= observed_correlation)
  return(p_value)
}

# Extract the data for each dialect
argentinian <- cor_data$`Spanish (Argentinian)`
european <- cor_data$`Spanish (European)`
mexican <- cor_data$`Spanish (Mexican)`
peruvian <- cor_data$`Spanish (Peruvian)`

# Create an empty data frame to store p-values
p_values <- data.frame(
  Dialect1 = character(),
  Dialect2 = character(),
  P_Value = numeric(),
  stringsAsFactors = FALSE
)

# Perform permutation tests for each pair of dialects
dialects <- list(argentinian, european, mexican, peruvian)
dialect_names <- c("Spanish (Argentinian)", "Spanish (European)", "Spanish (Mexican)", "Spanish (Peruvian)")

for (i in 1:length(dialects)) {
  for (j in i:length(dialects)) {
    if (i != j) {
      p_val <- perm_test(dialects[[i]], dialects[[j]])
      p_values <- data.frame(rbind(p_values, data.frame(Dialect1 = dialect_names[i], Dialect2 = dialect_names[j], P_Value = p_val)))
    }
  }
}
```

Regression 
```{r}
#Load gamlss library
library(gamlss)

#Clean sp_ws data frame to include only necessary rows
 sp_ws_minimal <- dplyr::select(sp_ws, age, production, language)

#Find prop_produced for each dialect
items_filtered <- filter(items, items$item_kind == 'word')

sp_ws_left_join <- left_join(sp_ws_minimal,(items_filtered |> group_by(language) |> summarise(n = n())))

sp_ws_prop_produced <- mutate(sp_ws_left_join, prop_produced = sp_ws_left_join$production / sp_ws_left_join$n)

#Run regression
gam_mod <- gamlss(prop_produced ~ pbm(age, lambda = 10000) * as.factor(language),
                  sigma.formula = ~ pbm(age, lambda = 10000) * as.factor(language),
                  data = sp_ws_prop_produced)
summary(gam_mod)
```

Fitting regression data to a curve 
```{r}
# Generate a sequence of ages for prediction
age_seq <- seq(min(sp_ws_prop_produced$age), max(sp_ws_prop_produced$age), by = 0.1)

# Create a new data frame for predictions
new_data <- expand.grid(age = age_seq, 
                        language = unique(sp_ws_prop_produced$language))

# Generate predictions from the model
new_data$predicted <- predict(gam_mod, newdata = new_data, type = "response")

# Plot the data and the fitted curve
ggplot(sp_ws_prop_produced, aes(x = age, y = prop_produced, color = language)) +
  geom_point() +
  geom_line(data = new_data, aes(x = age, y = predicted, color = language), linewidth = 1) +
  labs(title = "Predicted Proportion Produced by Age and Language",
       x = "Age",
       y = "Proportion Produced") +
  theme_minimal()
```

Fitting single language data to regression
```{r}t.
# Filter "d_ws" data frame to just European Spanish
Eu_Regression <- d_ws %>% 
  filter(language == "Spanish (European)")
# Convert TRUE/FALSE values to 1's and 0's
Eu_Regression$produces <- as.numeric(Eu_Regression$produces)
# Plot predicted data and original data points
ggplot(Eu_Regression, aes(x = age, y = produces)) + 
  geom_point() +
  stat_smooth(method = "glm", color = "green", se = FALSE, 
              method.args = list(family = binomial))

sp_ws_prop_produced_Eu <- sp_ws_prop_produced %>% 
  filter(language == "Spanish (European)")

ggplot(sp_ws_prop_produced_Eu, aes(x = age, y = prop_produced)) + 
  geom_point() +
  stat_smooth(method = "glm", color = "green", se = FALSE, 
              method.args = list(family = binomial))
```

Comparing identical/nonidentical surface forms
```{r}
# Filter "items" data-set to "words" only, then filter again so that it contains only those uni_lemmas contained in the "aoas" data frame
items_filtered <- filter(items, items$item_kind == 'word') %>% 
  filter(uni_lemma %in% c((clean_aoas$uni_lemma)))
# Arrange "uni_lemma" and "language" columns to match with order of said columns in "aoas" data frame
  arrange(items_filtered, uni_lemma, language)
# Trim dataframe to include only necessary columns
items_filtered <- items_filtered %>%
  dplyr::select(language, item_definition, uni_lemma)
# Clean up discrepancies and match up with AoA data in a CSV file. Then read into a new data frame
uni_lemma_aoa <- read.csv("cleaned_items_aoa.csv")
# Pivot into a wider dataframe which includes language, uni_lemma, and cleaned surface forms
cleaned_uni_lemma_wider <- uni_lemma_aoa %>%
  dplyr::select(language, uni_lemma, aoa, cleaned_item) %>%
  pivot_wider(names_from = language, values_from = cleaned_item, uni_lemma)
# Select for just European Spanish and Mexican Spanish
Eu_Mx <- cleaned_uni_lemma_wider %>% 
  dplyr::select(uni_lemma, `Spanish (European)`, `Spanish (Mexican)`)
#Join in AoA data
clean_aoas_Eu_Mx <- clean_aoas %>%
  dplyr::select(uni_lemma, `Spanish (European)`, `Spanish (Mexican)`) %>%
  left_join(Eu_Mx, join_by(uni_lemma))
# Filter for identical surface forms and calculate correlation
Eu_Mx_Identical <- clean_aoas_Eu_Mx %>% 
  filter(`Spanish (European).y` == `Spanish (Mexican).y`)
# Calculate correlation of AoA values
correlation_Eu_Mx_Identical <- cor(Eu_Mx_Identical$`Spanish (European).x`, Eu_Mx_Identical$`Spanish (Mexican).x`)
# Filter for non-identical surface forms
Eu_Mx_NonIdentical <- clean_aoas_Eu_Mx %>%
  filter(`Spanish (European).y` != `Spanish (Mexican).y`)
# Calculate correlation
correlation_Eu_Mx_NonIdentical <- cor(Eu_Mx_NonIdentical$`Spanish (European).x`, Eu_Mx_NonIdentical$`Spanish (Mexican).x`)
```

t-test for AoA differences
```{r}
# Generate a data frame with all AoA and uni_lemma values
uni_lemma_aoa_wider <- uni_lemma_aoa %>%
  dplyr::select(language, uni_lemma, aoa, cleaned_item) %>%
  pivot_wider(names_from = language, values_from = cleaned_item, uni_lemma)
uni_lemma_aoa_master <- clean_aoas %>%
  left_join(uni_lemma_aoa_wider, join_by(uni_lemma))
# Filter to identical and nonidentical surface forms for all dialect pairings
Eu_Ar_Identical <- uni_lemma_aoa_master %>%
  filter(`Spanish (European).y` == `Spanish (Argentinian).y`)
Eu_Ar_NonIdentical <- uni_lemma_aoa_master %>%
  filter(`Spanish (European).y` != `Spanish (Argentinian).y`)

Eu_Pr_Identical <- uni_lemma_aoa_master %>% 
  filter(`Spanish (European).y` == `Spanish (Peruvian).y`)
Eu_Pr_NonIdentical <- uni_lemma_aoa_master %>% 
  filter(`Spanish (European).y` != `Spanish (Peruvian).y`)

Mx_Ar_Identical <- uni_lemma_aoa_master %>% 
  filter(`Spanish (Mexican).y` == `Spanish (Argentinian).y`)
Mx_Ar_NonIdentical <- uni_lemma_aoa_master %>% 
  filter(`Spanish (Mexican).y` != `Spanish (Argentinian).y`)

Mx_Pr_Identical <- uni_lemma_aoa_master %>% 
  filter(`Spanish (Mexican).y` == `Spanish (Peruvian).y`)
Mx_Pr_NonIdentical <- uni_lemma_aoa_master %>% 
  filter(`Spanish (Mexican).y` != `Spanish (Peruvian).y`)

Pr_Ar_Identical <- uni_lemma_aoa_master %>% 
  filter(`Spanish (Peruvian).y` == `Spanish (Argentinian).y`)
Pr_Ar_NonIdentical <- uni_lemma_aoa_master %>% 
  filter(`Spanish (Peruvian).y` != `Spanish (Argentinian).y`)
# Generate vector of differences for each possible dialect pairing
dif_Eu_Mx_Identical <- Eu_Mx_Identical$`Spanish (European).x` - Eu_Mx_Identical$`Spanish (Mexican).x`
dif_Eu_Mx_NonIdentical <- Eu_Mx_NonIdentical$`Spanish (European).x` - Eu_Mx_NonIdentical$`Spanish (Mexican).x`

dif_Eu_Ar_Identical <- Eu_Ar_Identical$`Spanish (European).x`- Eu_Ar_Identical$`Spanish (Argentinian).x`
dif_Eu_Ar_NonIdentical <- Eu_Ar_NonIdentical$`Spanish (European).x` - Eu_Ar_NonIdentical$`Spanish (Argentinian).x`

dif_Eu_Pr_Identical <- Eu_Pr_Identical$`Spanish (European).x` - Eu_Pr_Identical$`Spanish (Peruvian).x`
dif_Eu_Pr_NonIdentical <- Eu_Pr_NonIdentical$`Spanish (European).x` - Eu_Pr_Nonidentical$`Spanish (Peruvian).x`

dif_Mx_Ar_Identical <- Mx_Ar_Identical$`Spanish (Mexican).x` - Mx_Ar_Identical$`Spanish (Argentinian).x`
dif_Mx_Ar_NonIdentical <- Mx_Ar_NonIdentical$`Spanish (Mexican).x` - Mx_Ar_NonIdentical$`Spanish (Argentinian).x`

dif_Mx_Pr_Identical <- Mx_Pr_Identical$`Spanish (Mexican).x` - Mx_Pr_Identical$`Spanish (Peruvian).x`
dif_Mx_Pr_NonIdentical <- Mx_Pr_NonIdentical$`Spanish (Mexican).x` - Mx_Pr_NonIdentical$`Spanish (Peruvian).x`

dif_Pr_Ar_Identical <- Pr_Ar_Identical$`Spanish (Peruvian).x` - Pr_Ar_Identical$`Spanish (Argentinian).x`
dif_Pr_Ar_NonIdentical <- Pr_Ar_NonIdentical$`Spanish (Peruvian).x` - Pr_Ar_NonIdentical$`Spanish (Argentinian).x`

# Perform a t-test for these differences and place p-values into a data frame
Identical_NonIdentical_p_values <- data.frame(
  Eu_Mx = c(t.test(dif_Eu_Mx_Identical, dif_Eu_Mx_NonIdentical)$p.value),
  Eu_Ar = c(t.test(dif_Eu_Ar_Identical, dif_Eu_Ar_NonIdentical)$p.value),
  Eu_Pr = c(t.test(dif_Eu_Pr_Identical, dif_Eu_Pr_NonIdentical)$p.value),
  Mx_Ar = c(t.test(dif_Mx_Ar_Identical, dif_Mx_Ar_NonIdentical)$p.value),
  Mx_Pr = c(t.test(dif_Mx_Pr_Identical, dif_Mx_Pr_NonIdentical)$p.value),
  Pr_Ar = c(t.test(dif_Pr_Ar_Identical, dif_Pr_Ar_NonIdentical)$p.value)
)
```



## Step 1: Fit the 2PL model
We fit the 2PL model using `itemtype = "2PL"`.
```{r}
modstr <- glue("F = 1 - {ncol(eu_ws)}")
eu_ws_cleaned <- dplyr::select(eu_ws, comprehension, production)
Spanish_European_2PL <- mirt(eu_ws_cleaned,
                model = modstr,
                itemtype = "2PL",
                verbose = FALSE)

# model coefficients
coef.2pl_Spanish_European_2PL <- as_tibble(coef(Spanish_European_2PL, simplify = TRUE)$items
                      rownames = "definition")
```

# model coefficients
coef.2pl <- as_tibble(coef(fit.2pl, simplify = TRUE)$items,
                      rownames = "definition")
coef.2pl
```
Now we see that discrimination (`a1`) varies across items.
Higher discriminability estimates indicate that the item has a better ability to tell the difference between different levels of latent ability, as will be made clearer in the ICC plots.

## Step 2: Plot the Item Characteristic Curves 
```{r}
tracePlot(fit.2pl, facet = FALSE, legend = TRUE) + scale_color_brewer(palette = "Set3")
```
  
Unlike the ICCs for the 1PL model, the ICCs for the 2PL model do not all have the same shape. 
Item curves which are more "spread out" indicate lower discriminability (i.e., that individuals of a range of ability levels have some probability of getting the item correct). 
Compare this to an item with high discriminability (steep slope): for this item, we have a better estimate of the individual's latent ability based on whether they got the question right or wrong.

*A note about difficulty*: Because of the differing slopes, the rank-order of item difficulty changes across different latent ability levels. We can see that item 9 is generally still the most difficult item (i.e. lowest probability of getting correct for most latent trait values, up until about $\theta=3.3$). 

## Step 3: Plot the Item Information Curves for Items & Test
```{r}
itemInfoPlot(fit.2pl, facet = FALSE, legend = TRUE) + scale_color_brewer(palette = "Set3")
```
  
The item IICs demonstrate that some items provide more information about latent ability for different ability levels. 
The higher the item discriminability estimate, the more information an item provides about ability levels around the point where there is a .5 probability of getting the item right (i.e. the steepest point in the ICC slope). 
For example, item 9 clearly provides the most information at high ability levels, around $\theta=2.3$, but almost no information about low ability levels (< -1) because the item is already too hard for those participants. 
In contrast, item 8, which has low discriminability, doesn't give very much information overall, but covers a wide range of ability levels.

Next, we plot the item information curve for the whole test. This is the sum of all the item IICs above.
```{r}
testInfoPlot(fit.2pl)
```
  
The IIC for the whole test shows that the test provides the most information for slightly-higher-than average ability levels (about $\theta=1$), but does not provide much information about extremely high or low ability levels.

## Step 4: Examine fit of the 2PL model
Next, we test how well the 2PL model fits the data.
```{r}
itemfit(fit.2pl, na.rm = TRUE)
```

Item 9 is still problematic, as before.

## Step 5: Estimate & Plot Ability Scores 

Estimate the individual latent ability scores using the `factor.scores()` function in the `ltm` library.
```{r}
theta.2pl <- fscores(fit.2pl)

head(theta.2pl, 10)
```

Plot the density curve of the estimated ability scores
```{r}
personDist(fit.2pl)
```

